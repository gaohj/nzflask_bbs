# 爬虫第4天  

* 多线程爬虫  
* 动态网页爬虫 
* 绕过图形验证码
* 字体反爬  



## 多线程 爬虫  

### 深度优先 

```python
#encoding:utf-8
import re
import requests
#深度爬取 递归
from lxml import etree

headers = {
    "User-Agent":"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50"
}


def getHTML(url):
    try:
        res = requests.get(url,headers=headers)
        # print(res.content.decode('utf-8'))
        return res.content.decode('utf-8')
    except:
        return ""

def get_son_url(url):

    text = getHTML(url) #获取页面内容
    html = etree.HTML(text)
    #规则
    aList = html.xpath("//a/@href")
    return aList
def main(url):
    if deep_dict[url] > 4:
        return
    print("\t" * deep_dict[url],"当前层级:%d" % deep_dict[url])
    #获取网页子url
    sonurl_list = get_son_url(url)
    for sonurl in sonurl_list:
        #过滤有效链接
        if sonurl.startswith('http') or sonurl.startswith('https'):
            if sonurl not in deep_dict:#过滤重复的url
                deep_dict[sonurl] = deep_dict[url] + 1
                main(sonurl) #递归爬取子url
if __name__ == "__main__":
    url = "https://www.so.com/s?q=%E5%B2%9B%E5%9B%BD%E7%A7%8D%E5%AD%90"
    deep_dict = {}
    deep_dict[url] = 1 #默认层级为1
    main(url)


```

### 广度优先 

```
#encoding:utf-8
import re
import requests
#深度爬取 递归
from lxml import etree

headers = {
    "User-Agent":"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50"
}


def getHTML(url):
    try:
        res = requests.get(url,headers=headers)
        # print(res.content.decode('utf-8'))
        return res.content.decode('utf-8')
    except:
        return ""

def get_son_url(url):

    text = getHTML(url) #获取页面内容
    html = etree.HTML(text)
    #规则
    aList = html.xpath("//a/@href")
    return aList
def main(startUrl):
    #用列表 模拟队列
    url_queue = []
    url_queue.append(startUrl)
    while len(url_queue) > 0:
        url = url_queue.pop(0)  # 每次取出列表第一个
        print("\t" * deep_dict[url], "当前层级:%d" % deep_dict[url])
        if deep_dict[url] < 4:
            sonList = get_son_url(url)  # 获取子url列表
            for son_url in sonList:
                # 过滤有效的url
                if son_url.startswith('http') or son_url.startswith('https'):
                    if son_url not in deep_dict:  # 过滤重复url
                        deep_dict[son_url] = deep_dict[url] + 1  # 层级加1
                        url_queue.append(son_url)  # 将子url进入队列
if __name__ == "__main__":
    url = "https://www.so.com/s?q=%E5%B2%9B%E5%9B%BD%E7%A7%8D%E5%AD%90"
    deep_dict = {}
    deep_dict[url] = 1 #默认层级为1
    main(url)


```



### 函数 线程方式

```python
import time
import threading
def driving():
    for x in range(3):
        print('%s正在开车' % threading.current_thread()) #当前线程
        time.sleep(2)


def loling():
    for x in range(3):
        print('%s正在撸' % threading.current_thread()) #当前线程
        time.sleep(2)


def main():
    t1 = threading.Thread(target=driving) #实例化线程 并且制定要做什么
    t2 = threading.Thread(target=loling)

    t1.start()
    t2.start()
    print(threading.enumerate()) #查看进程的数量
if __name__ == "__main__":
    main()
```



### 类多线程

```python
import time
import threading
class DrivingThread(threading.Thread):
    def run(self):
        for x in range(3):
            print('%s正在开车' % threading.current_thread())  # 当前线程
            time.sleep(2)

class LolingThread(threading.Thread):
    def run(self):
        for x in range(3):
            print('%s正在撸' % threading.current_thread()) #当前线程
            time.sleep(2)


def main():
    t1 = DrivingThread() #实例化线程 并且制定要做什么
    t2 = LolingThread()

    t1.start()
    t2.start()
    print(threading.enumerate()) #查看线程的数量
if __name__ == "__main__":
    main()
```



### 锁机制

```python
import threading

VALUE = 0
gLock = threading.Lock()

def add_value():
    global VALUE
    gLock.acquire()
    for x in range(10000000):
        VALUE +=1
    gLock.release()
    print("value:%d" % VALUE)

def main():
    for x in range(2):
        t = threading.Thread(target=add_value)
        t.start()

if __name__ == "__main__":
     main()

```



### 生产者和消费者  锁 Lock版   

```python
import threading
import random
import time
gMoney = 10000
gLock = threading.Lock()

gTotalTimes = 10
gTime = 0

# 生产者
class Producer(threading.Thread):
    def run(self):
        global gMoney
        global gTime
        while True:
            money= random.randint(1000,10000)
            gLock.acquire() #上锁
            if gTime >= gTotalTimes:
                gLock.release()
                break
            gMoney += money
            print("%s挣了%d元钱,余额%d元钱" % (threading.current_thread(),money,gMoney))
            gTime +=1
            gLock.release() #释放锁
            time.sleep(0.5)
#消费者
class Consumer(threading.Thread):
    def run(self):
        global gMoney
        while True:
            money = random.randint(1000,10000)
            gLock.acquire()
            if gMoney >= money:
                gMoney -= money
                print("%s消费了%d元钱,余额%d元钱" % (threading.current_thread(), money, gMoney))
            else:
                if gTime >= gTotalTimes:
                    gLock.release()
                    break
                print("%s消费了%d元钱,余额%d元钱,余额不足" % (threading.current_thread(), money, gMoney))
            gLock.release()
            time.sleep(0.5)

def main():

    for x in range(3):
        t = Consumer(name="消费者线程%d" % x)
        t.start()

    for x in range(3):
        t = Producer(name="生产者线程%d" % x)
        t.start()

if __name__ == "__main__":
    main()
```

> 上面  通过 while True 死循环  然后上锁 判断 余额是否大于消费额     频繁的上锁释放锁会导致 CPU资源消耗过大 采用  threading.Condition 可以在没有数据的时候 处于阻塞状态   一旦生产者有数据了  就会通知正在等待的线程  这样的话 省掉无用频繁的  频繁上锁释放锁  这个 其实类似于 threading.Lock   可以上锁 释放锁   



### Condition 版的生产者和消费者  

```
import threading
import random
import time
gMoney = 10000
gCondition = threading.Condition()

#生产者 消费者是多线程的一种模式

gTotalTimes = 10
gTime = 0

# 生产者
class Producer(threading.Thread):
    def run(self):
        global gMoney
        global gTime
        global gCondition
        while True:
            money= random.randint(1000,10000)
            gCondition.acquire() #上锁
            if gTime >= gTotalTimes:
                gCondition.release()
                break
            gMoney += money
            print("%s挣了%d元钱,余额%d元钱" % (threading.current_thread(),money,gMoney))
            gTime +=1
            time.sleep(0.5)
            gCondition.notify_all()
            gCondition.release() #释放锁

#消费者
class Consumer(threading.Thread):
    def run(self):
        global gMoney
        global gCondition
        while True:
            money = random.randint(1000,10000)
            gCondition.acquire()
            while gMoney < money:
                if gTime >= gTotalTimes:
                    gCondition.release()
                    return
                print("%s消费了%d元钱,余额%d元钱,余额不足" % (threading.current_thread(), money, gMoney))
                gCondition.wait() #阻塞等待
            gMoney -= money
            print("%s消费了%d元钱,余额%d元钱" % (threading.current_thread(), money, gMoney))
            time.sleep(0.5)
            gCondition.release()

def main():

    for x in range(3):
        t = Consumer(name="消费者线程%d" % x)
        t.start()

    for x in range(3):
        t = Producer(name="生产者线程%d" % x)
        t.start()

if __name__ == "__main__":
    main()
```

1. `acquire`:上锁
2. `release`:释放锁
3. `wait`:当前线程处在等待状态  并且会释放锁  可以被 notify 和 notify_all 函数 唤醒 被唤醒后继续等待上锁，上锁了 开始执行 下面的代码 
4. `notify`: 通知正在等待的线程  默认是第一个  
5. `notify_all` :通知所有正在等待的线程 notify 、notify_all 不会释放锁 必须在释放锁之前进行调用  重点 



### Queue 线程安全队列  

> 在线程中访问全局变量 ，加锁是经常的  如果想把数据存储在队列中 可以使用 python内置的线程安全模块queue   FIFO 先进先出  Queue   LIFO  后入先出   LifoQueue 这些都是原子操作  要么不做 要做就做完 能够在多线程中直接使用 

1. 初始化Queue（maxsize） 先进先出 队列 
2. qsize()  队列大小 
3. empty() 是否为空
4. full() 队列是否满了 
5. get() 从队列中取最后一个数据
6. put() 将一个数据放入队列中



# 动态网页数据抓取

## 什么是AJAX：

AJAX（Asynchronouse JavaScript And XML）异步JavaScript和XML。过在后台与服务器进行少量数据交换，Ajax 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。传统的网页（不使用Ajax）如果需要更新内容，必须重载整个网页页面。因为传统的在传输数据格式方面，使用的是`XML`语法。因此叫做`AJAX`，其实现在数据交互基本上都是使用`JSON`。使用AJAX加载的数据，即使使用了JS，将数据渲染到了浏览器中，在`右键->查看网页源代码`还是不能看到通过ajax加载的数据，只能看到使用这个url加载的html代码。

## 获取ajax数据的方式：

1. 直接分析ajax调用的接口。然后通过代码请求这个接口。
2. 使用Selenium+chromedriver模拟浏览器行为获取数据。

| 方式     | 优点                                                         | 缺点                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 分析接口 | 直接可以请求到数据。不需要做一些解析工作。代码量少，性能高。 | 分析接口比较复杂，特别是一些通过js混淆的接口，要有一定的js功底。容易被发现是爬虫。 |
| selenium | 直接模拟浏览器的行为。浏览器能请求到的，使用selenium也能请求到。爬虫更稳定。 | 代码量多。性能低。                                           |

## Selenium+chromedriver获取动态数据：

`Selenium`相当于是一个机器人。可以模拟人类在浏览器上的一些行为，自动处理浏览器上的一些行为，比如点击，填充数据，删除cookie等。`chromedriver`是一个驱动`Chrome`浏览器的驱动程序，使用他才可以驱动浏览器。当然针对不同的浏览器有不同的driver。以下列出了不同浏览器及其对应的driver：

1. Chrome：<https://sites.google.com/a/chromium.org/chromedriver/downloads>
2. Firefox：<https://github.com/mozilla/geckodriver/releases>
3. Edge：<https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/>
4. Safari：<https://webkit.org/blog/6900/webdriver-support-in-safari-10/>

## 安装Selenium和chromedriver：

1. 安装Selenium：

   `Selenium`有很多语言的版本，有java、ruby、python等。我们下载python版本的就可以了。

   ```
    pip install selenium
   ```

2. 安装`chromedriver`：下载完成后，放到不需要权限的纯英文目录下就可以了。

### 快速入门：

现在以一个简单的获取百度首页的例子来讲下`Selenium`和`chromedriver`如何快速入门：

```
from selenium import webdriver

# chromedriver的绝对路径
driver_path = r'D:\ProgramApp\chromedriver\chromedriver.exe'

# 初始化一个driver，并且指定chromedriver的路径
driver = webdriver.Chrome(executable_path=driver_path)
# 请求网页
driver.get("https://www.baidu.com/")
# 通过page_source获取网页源代码
print(driver.page_source)
```

### selenium常用操作：

更多教程请参考：<http://selenium-python.readthedocs.io/installation.html#introduction>

#### 关闭页面：

1. `driver.close()`：关闭当前页面。
2. `driver.quit()`：退出整个浏览器。

#### 定位元素：

1. `find_element_by_id`：根据id来查找某个元素。等价于：

   ```
    submitTag = driver.find_element_by_id('su')
    submitTag1 = driver.find_element(By.ID,'su')
   ```

2. `find_element_by_class_name`：根据类名查找元素。 等价于：

   ```
    submitTag = driver.find_element_by_class_name('su')
    submitTag1 = driver.find_element(By.CLASS_NAME,'su')
   ```

3. `find_element_by_name`：根据name属性的值来查找元素。等价于：

   ```
    submitTag = driver.find_element_by_name('email')
    submitTag1 = driver.find_element(By.NAME,'email')
   ```

4. `find_element_by_tag_name`：根据标签名来查找元素。等价于：

   ```
    submitTag = driver.find_element_by_tag_name('div')
    submitTag1 = driver.find_element(By.TAG_NAME,'div')
   ```

5. `find_element_by_xpath`：根据xpath语法来获取元素。等价于：

   ```
    submitTag = driver.find_element_by_xpath('//div')
    submitTag1 = driver.find_element(By.XPATH,'//div')
   ```

6. `find_element_by_css_selector`：根据css选择器选择元素。等价于：

   ```
    submitTag = driver.find_element_by_css_selector('//div')
    submitTag1 = driver.find_element(By.CSS_SELECTOR,'//div')
   ```

   要注意，`find_element`是获取第一个满足条件的元素。`find_elements`是获取所有满足条件的元素。

#### 操作表单元素：

1. 操作输入框：分为两步。第一步：找到这个元素。第二步：使用`send_keys(value)`，将数据填充进去。示例代码如下：

   ```
    inputTag = driver.find_element_by_id('kw')
    inputTag.send_keys('python')
   ```

   使用`clear`方法可以清除输入框中的内容。示例代码如下：

   ```
    inputTag.clear()
   ```

2. 操作checkbox：因为要选中`checkbox`标签，在网页中是通过鼠标点击的。因此想要选中`checkbox`标签，那么先选中这个标签，然后执行`click`事件。示例代码如下：

   ```
    rememberTag = driver.find_element_by_name("rememberMe")
    rememberTag.click()
   ```

3. 选择select：select元素不能直接点击。因为点击后还需要选中元素。这时候selenium就专门为select标签提供了一个类`selenium.webdriver.support.ui.Select`。将获取到的元素当成参数传到这个类中，创建这个对象。以后就可以使用这个对象进行选择了。示例代码如下：

   ```
    from selenium.webdriver.support.ui import Select
    # 选中这个标签，然后使用Select创建对象
    selectTag = Select(driver.find_element_by_name("jumpMenu"))
    # 根据索引选择
    selectTag.select_by_index(1)
    # 根据值选择
    selectTag.select_by_value("http://www.95yueba.com")
    # 根据可视的文本选择
    selectTag.select_by_visible_text("95秀客户端")
    # 取消选中所有选项
    selectTag.deselect_all()
   ```

4. 操作按钮：操作按钮有很多种方式。比如单击、右击、双击等。这里讲一个最常用的。就是点击。直接调用`click`函数就可以了。示例代码如下：

   ```
    inputTag = driver.find_element_by_id('su')
    inputTag.click()
   ```

#### 行为链：

有时候在页面中的操作可能要有很多步，那么这时候可以使用鼠标行为链类`ActionChains`来完成。比如现在要将鼠标移动到某个元素上并执行点击事件。那么示例代码如下：

```
inputTag = driver.find_element_by_id('kw')
submitTag = driver.find_element_by_id('su')

actions = ActionChains(driver)
actions.move_to_element(inputTag)
actions.send_keys_to_element(inputTag,'python')
actions.move_to_element(submitTag)
actions.click(submitTag)
actions.perform()
```

还有更多的鼠标相关的操作。

- click_and_hold(element)：点击但不松开鼠标。
- context_click(element)：右键点击。
- double_click(element)：双击。 更多方法请参考：<https://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains>

#### Cookie操作：

1. 获取所有的cookie：

   ```
    for cookie in driver.get_cookies():
        print(cookie)
   ```

2. 根据cookie的key获取value：

   ```
    value = driver.get_cookie(key)
   ```

3. 删除所有的cookie：

   ```
    driver.delete_all_cookies()
   ```

4. 删除某个cookie：

   ```
    driver.delete_cookie(key)
   ```

#### 页面等待：

现在的网页越来越多采用了 Ajax 技术，这样程序便不能确定何时某个元素完全加载出来了。如果实际页面等待时间过长导致某个dom元素还没出来，但是你的代码直接使用了这个WebElement，那么就会抛出NullPointer的异常。为了解决这个问题。所以 Selenium 提供了两种等待方式：一种是隐式等待、一种是显式等待。

1. 隐式等待：调用`driver.implicitly_wait`。那么在获取不可用的元素之前，会先等待10秒中的时间。示例代码如下：

   ```
   driver = webdriver.Chrome(executable_path=driver_path)
   driver.implicitly_wait(10)
   # 请求网页
   driver.get("https://www.douban.com/")
   ```

2. 显示等待：显示等待是表明某个条件成立后才执行获取元素的操作。也可以在等待的时候指定一个最大的时间，如果超过这个时间那么就抛出一个异常。显示等待应该使用`from selenium.webdriver.support import expected_conditions as EC`期望的条件和`selenium.webdriver.support.ui.WebDriverWait`来配合完成。示例代码如下：

   ```
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
   
    driver = webdriver.Firefox()
    driver.get("http://somedomain/url_that_delays_loading")
    try:
        element = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, "myDynamicElement"))
        )
    finally:
        driver.quit()
   ```

3. 一些其他的等待条件：

   - presence_of_element_located：某个元素已经加载完毕了。

   - presence_of_all_emement_located：网页中所有满足条件的元素都加载完毕了。

   - element_to_be_cliable：某个元素是可以点击了。

     更多条件请参考：<http://selenium-python.readthedocs.io/waits.html>

#### 切换页面：

有时候窗口中有很多子tab页面。这时候肯定是需要进行切换的。`selenium`提供了一个叫做`switch_to_window`来进行切换，具体切换到哪个页面，可以从`driver.window_handles`中找到。示例代码如下：

```
# 打开一个新的页面
self.driver.execute_script("window.open('"+url+"')")
# 切换到这个新的页面中
self.driver.switch_to_window(self.driver.window_handles[1])
```

#### 设置代理ip：

有时候频繁爬取一些网页。服务器发现你是爬虫后会封掉你的ip地址。这时候我们可以更改代理ip。更改代理ip，不同的浏览器有不同的实现方式。这里以`Chrome`浏览器为例来讲解：

```
from selenium import webdriver

options = webdriver.ChromeOptions()
options.add_argument("--proxy-server=http://110.73.2.248:8123")
driver_path = r"D:\ProgramApp\chromedriver\chromedriver.exe"
driver = webdriver.Chrome(executable_path=driver_path,chrome_options=options)

driver.get('http://httpbin.org/ip')
```

#### `WebElement`元素：

`from selenium.webdriver.remote.webelement import WebElement`类是每个获取出来的元素的所属类。
有一些常用的属性：

1. get_attribute：这个标签的某个属性的值。
2. screentshot：获取当前页面的截图。这个方法只能在`driver`上使用。
   `driver`的对象类，也是继承自`WebElement`。
   更多请阅读相关源代码。