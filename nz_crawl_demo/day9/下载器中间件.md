## 下载器中间件    

> 引擎和下载之间通信的中间件  设置代理 更换请求头 selenium 等 反反爬措施 
>
> process_request  请求发送之前执行的方法  
>
> process_response 数据下载到引擎之前 执行的方法  



## process_request  

> 在这里设置随机代理IP  

### 参数 

* request 发送请求的request对象 
* spider   发送请求的爬虫对象 

### 返回值   

* None  会继续处理 request  执行其它中间件中的相应方法 直到遇到 合适的 下载器处理函数被调用 
* Response对象  那么就不再调用其它的process_request方法了  直接返回给引擎这个Response对象 已经激活的process_response 方法  每个response 返回的时候 调用   
* Request对象   不再用之前的request对象去发送请求 而是根据返回的request对象 返回数据   
* 抛出异常  则调用 process_exception方法





## process_response

> 数据到引擎中间 会执行的方法  

### 参数 

* request request对象 
* response  被处理的response对象  
* spider   发送请求的爬虫对象 

### 返回值  

* Response object 将新的response对象传给中间件   一步步传给爬虫 
* Request object  下载器链就被切断了  重新进行下载 
* IgnoreRequest 抛异常  那么就会调用scrapy.Request() 的 errback  如果没有指定这个方法  那么就会抛异常 





