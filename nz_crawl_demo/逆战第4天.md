# 爬虫   

* 网络请求 
  * 虚拟环境
  * 爬虫前奏 
  * http协议和谷歌浏览器  
  * urllib库  
  * requests库 
* 数据提取  
  * xpath
  * bs4 
  * 正则表达式 、re 模块 
* 数据存储 
  * csv 
  * mysql 
  * mongodb 
* 爬虫进阶  
  * 多线程 协程   
  * 验证码识别  
  * 字体反爬 
  * selenium  
  * 反反爬
* scrapy  
* scrapy-redis 



## 爬虫前奏  

### 生活中的爬虫  

* 百度 360搜索 bing 谷歌 等搜索引擎 
* 掘金等社区 不全部生产内容而是内容的搬运工    
* 盖的排行、惠惠购物助手  
* 数据分析之前数据来源  数据冰山    
* 抢票软件 

### 什么是爬虫 

> 一个模拟人类请求网站行为的程序  

### 聚焦爬虫和通用爬虫  

* 通用爬虫 
  * 百度、谷歌 
* 聚焦爬虫 
  * 面向特定需求的爬虫程序 对数据进行筛选和处理 保证只抓取与需求相关的数据

### python爬虫的优势  

* php 天生做web 异步多线程支持不是特别好 速度和效率 不如python强 
* java 生态圈完善，python最大竞争对手，但是代码量特别大，重构成本太高
* c/c++  速度快  但是学习和开发成太高  一个小的功能也得花费半天的时间   
* Python 语法优美 代码简介 丰富的请求和解析库  还有scrapy 框架 开发效率大大提升



### http 和https 协议 

* http  80 
* https  443 



### 在浏览器发送一个http请求的过程  

1. 浏览器 输入url地址 回车  发送http请求  get 和post、put等请求方式   
2. 携带 head头信息（request信息）  发送给服务器  服务器返回之后 head头中 会有（response）信息给浏览器   
3. 浏览器分析 head头中的 response headers 如果发现是个 html 那么就解析页面 另外如果还有别的 比如图片 css 等 那么就会再次发送请求   
4. 当所有的文件都下载成功以后 根据html语法结构  就会完整的显示页面   



### 请求常见的参数  

> request headers  和 reponse headers   

`user-agent` ： 浏览器名称   如果你不携带这个参数 向服务器发送请求 服务器接收到的 user-agent 就是python 判断你这个请求时爬虫  就不返回任何值  所以我们要携带这个参数  避免 被拒绝  django中的  commonmiddleware就是 如果user-agent 为空 那么直接403    

`referer`: 表明这个请求是从哪里过来的 如果 不是从指定的页面过看来 那么不返回   也是一个反爬虫技术  

`cookie`:http请求时无状态的  cookie 保存身份信息  

`accept`:浏览器跟无服务一个约定 我支持什么类型的文件  不支持什么类型的文件 









 

