# 下载文件和图片

Scrapy为下载item中包含的文件(比如在爬取到产品时，同时也想保存对应的图片)提供了一个可重用的`item pipelines`。这些`pipeline`有些共同的方法和结构(我们称之为`media pipeline`)。一般来说你会使用`Files Pipeline`或者`Images Pipeline`。

## 为什么要选择使用`scrapy`内置的下载文件的方法：

1. 避免重新下载最近已经下载过的文件。
2. 可以方便的指定文件存储的路径。
3. 可以将下载的图片转换成通用的格式。比如png或jpg。
4. 可以方便的生成缩略图。
5. 可以方便的检测图片的宽和高，确保他们满足最小限制。
6. 异步下载，效率非常高。

## 下载文件的`Files Pipeline`：

当使用`Files Pipeline`下载文件的时候，按照以下步骤来完成： 

1. 定义好一个`Item`，然后在这个`item`中定义两个属性，分别为`file_urls`以及`files`。`file_urls`是用来存储需要下载的文件的url链接，需要给一个列表。 
2. 当文件下载完成后，会把文件下载的相关信息存储到`item`的`files`属性中。比如下载路径、下载的url和文件的校验码等。 
3. 在配置文件`settings.py`中配置`FILES_STORE`，这个配置是用来设置文件下载下来的路径。 
4. 启动`pipeline`：在`ITEM_PIPELINES`中设置`scrapy.pipelines.files.FilesPipeline:1`。

## 下载图片的`Images Pipeline`：

当使用`Images Pipeline`下载文件的时候，按照以下步骤来完成： 

1. 定义好一个`Item`，然后在这个`item`中定义两个属性，分别为`image_urls`以及`images`。`image_urls`是用来存储需要下载的图片的url链接，需要给一个列表。 
2. 当文件下载完成后，会把文件下载的相关信息存储到`item`的`images`属性中。比如下载路径、下载的url和图片的校验码等。 
3. 在配置文件`settings.py`中配置`IMAGES_STORE`，这个配置是用来设置图片下载下来的路径。 
4. 启动`pipeline`：在`ITEM_PIPELINES`中设置`scrapy.pipelines.images.ImagesPipeline:1`。